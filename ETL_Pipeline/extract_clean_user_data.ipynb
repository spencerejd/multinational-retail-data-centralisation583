{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Milestone 2 Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.database_utils import DatabaseConnector\n",
    "from scripts.data_cleaning import DataCleaning\n",
    "from scripts.data_extraction import DataExtractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create our DataFrame which will contain the user data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Called 'init_db_engine' method for database engine initialisation.\n",
      "Read credentials from db_creds.yaml\n",
      "Database credentials now stored in 'credentials' variable.\n",
      "Database engine initialised successfully with the credentials in db_creds.yaml.\n",
      "Data extracted from the 'legacy_users' table and into a DataFrame.\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the DatabaseConnector class\n",
    "database = DatabaseConnector()\n",
    "# Initialise engine with yaml_file_path set to 'default'\n",
    "database_engine = database.init_db_engine()\n",
    "# Create an instance of the DataExtractor class\n",
    "data_extractor = DataExtractor()\n",
    "# Extract data from table 'legacy_users' and store it in a DataFrame\n",
    "df = data_extractor.read_rds_table(database_engine, 'legacy_users')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, clean the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15320 entries, 0 to 15319\n",
      "Data columns (total 12 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   index          15320 non-null  int64 \n",
      " 1   first_name     15320 non-null  object\n",
      " 2   last_name      15320 non-null  object\n",
      " 3   date_of_birth  15320 non-null  object\n",
      " 4   company        15320 non-null  object\n",
      " 5   email_address  15320 non-null  object\n",
      " 6   address        15320 non-null  object\n",
      " 7   country        15320 non-null  object\n",
      " 8   country_code   15320 non-null  object\n",
      " 9   phone_number   15320 non-null  object\n",
      " 10  join_date      15320 non-null  object\n",
      " 11  user_uuid      15320 non-null  object\n",
      "dtypes: int64(1), object(11)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame cleaning operation initiated.\n",
      "DataFrame cleaned successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the DataCleaning class, with our DataFrame passed as an argument\n",
    "data_cleaner = DataCleaning(df)\n",
    "# Clean the DataFrame\n",
    "cleaned_df = data_cleaner.clean_user_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['DE', 'GB', 'US'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df['country_code'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 15284 entries, 0 to 1249\n",
      "Data columns (total 11 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   first_name     15284 non-null  object        \n",
      " 1   last_name      15284 non-null  object        \n",
      " 2   date_of_birth  15284 non-null  datetime64[ns]\n",
      " 3   company        15284 non-null  object        \n",
      " 4   email_address  15284 non-null  object        \n",
      " 5   address        15284 non-null  object        \n",
      " 6   country        15284 non-null  object        \n",
      " 7   country_code   15284 non-null  object        \n",
      " 8   phone_number   15284 non-null  object        \n",
      " 9   join_date      15284 non-null  datetime64[ns]\n",
      " 10  user_uuid      15284 non-null  object        \n",
      "dtypes: datetime64[ns](2), object(9)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "cleaned_df.info()\n",
    "\n",
    "# Can you confirm how many user_uuids should be found in the order_table?\n",
    "# This SQL query SELECT COUNT(DISTINCT user_uuid) FROM orders_table; states that it is 15284.\n",
    "# So the cleaning operation should result in 15284 non-null values in total?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [first_name, last_name, date_of_birth, company, email_address, address, country, country_code, phone_number, join_date, user_uuid]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Assuming cleaned_df is your dataframe\n",
    "\n",
    "# Filter the dataframe to include only rows with at least one NaN value\n",
    "rows_with_null = cleaned_df[cleaned_df.isna().any(axis=1)]\n",
    "\n",
    "# Display the resulting rows\n",
    "print(rows_with_null)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [first_name, last_name, date_of_birth, company, email_address, address, country, country_code, phone_number, join_date, user_uuid]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Count number of rows in the cleaned_df\n",
    "# df.info()\n",
    "# cleaned_df.info()\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# string_rows = cleaned_df[cleaned_df['join_date'].map(lambda x: isinstance(x, str))] \n",
    "# print(string_rows['join_date'])\n",
    "\n",
    "# # Sort and reverse the unique join dates\n",
    "# sorted_unique_join_dates = sorted(string_rows['join_date'].unique(), reverse=True)\n",
    "# print(sorted_unique_join_dates)\n",
    "\n",
    "\n",
    "duplicate_rows = cleaned_df[cleaned_df.duplicated(subset=['user_uuid'])]\n",
    "print(duplicate_rows)\n",
    "# # Assuming df is your DataFrame\n",
    "# unique_sorted_values = sorted(cleaned_df['user_uuid'].unique())\n",
    "\n",
    "# # Display the sorted unique values\n",
    "# print(\"Sorted Unique Values:\", unique_sorted_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the cleaned DataFrame to the local database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Called 'init_db_engine' method for database engine initialisation.\n",
      "Read credentials from rds_upload_db_creds.yaml\n",
      "Database credentials now stored in 'credentials' variable.\n",
      "Database engine initialised successfully with the credentials in rds_upload_db_creds.yaml.\n",
      "Data uploaded to the 'dim_users' table successfully.\n"
     ]
    }
   ],
   "source": [
    "# Now let's initialise the engine that we will upload our DataFrame to\n",
    "\n",
    "# We will set the 'yaml_file_path' to ensure the connection is made to the upload database engine\n",
    "upload_engine = database.init_db_engine(yaml_file_path='rds_upload_db_creds.yaml')\n",
    "\n",
    "# Upload 'cleaned_df' to our initialised engine\n",
    "database.upload_to_db(cleaned_df, table_name='dim_users')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
